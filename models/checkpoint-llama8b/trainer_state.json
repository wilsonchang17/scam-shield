{
  "best_metric": 2.7593941688537598,
  "best_model_checkpoint": "training_newest_aug/checkpoint-2250",
  "epoch": 14.978969072164949,
  "eval_steps": 50,
  "global_step": 2265,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13195876288659794,
      "grad_norm": 0.7150712609291077,
      "learning_rate": 3e-06,
      "loss": 3.822,
      "step": 20
    },
    {
      "epoch": 0.2639175257731959,
      "grad_norm": 0.7491768598556519,
      "learning_rate": 6e-06,
      "loss": 3.7897,
      "step": 40
    },
    {
      "epoch": 0.32989690721649484,
      "eval_loss": 3.7474653720855713,
      "eval_runtime": 141.4268,
      "eval_samples_per_second": 15.245,
      "eval_steps_per_second": 1.909,
      "step": 50
    },
    {
      "epoch": 0.3958762886597938,
      "grad_norm": 0.8370152711868286,
      "learning_rate": 9e-06,
      "loss": 3.6959,
      "step": 60
    },
    {
      "epoch": 0.5278350515463918,
      "grad_norm": 0.8368687033653259,
      "learning_rate": 1.2e-05,
      "loss": 3.6164,
      "step": 80
    },
    {
      "epoch": 0.6597938144329897,
      "grad_norm": 0.908973753452301,
      "learning_rate": 1.5e-05,
      "loss": 3.4438,
      "step": 100
    },
    {
      "epoch": 0.6597938144329897,
      "eval_loss": 3.3732810020446777,
      "eval_runtime": 142.1747,
      "eval_samples_per_second": 15.164,
      "eval_steps_per_second": 1.899,
      "step": 100
    },
    {
      "epoch": 0.7917525773195876,
      "grad_norm": 0.6974666118621826,
      "learning_rate": 1.8e-05,
      "loss": 3.3443,
      "step": 120
    },
    {
      "epoch": 0.9237113402061856,
      "grad_norm": 0.5077736377716064,
      "learning_rate": 2.1e-05,
      "loss": 3.249,
      "step": 140
    },
    {
      "epoch": 0.9896907216494846,
      "eval_loss": 3.20407772064209,
      "eval_runtime": 141.784,
      "eval_samples_per_second": 15.206,
      "eval_steps_per_second": 1.904,
      "step": 150
    },
    {
      "epoch": 1.0581443298969073,
      "grad_norm": 0.5165467262268066,
      "learning_rate": 2.4e-05,
      "loss": 3.3329,
      "step": 160
    },
    {
      "epoch": 1.1901030927835052,
      "grad_norm": 0.4106370210647583,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.147,
      "step": 180
    },
    {
      "epoch": 1.3220618556701031,
      "grad_norm": 0.4165462553501129,
      "learning_rate": 3e-05,
      "loss": 3.151,
      "step": 200
    },
    {
      "epoch": 1.3220618556701031,
      "eval_loss": 3.1115880012512207,
      "eval_runtime": 142.3679,
      "eval_samples_per_second": 15.144,
      "eval_steps_per_second": 1.896,
      "step": 200
    },
    {
      "epoch": 1.454020618556701,
      "grad_norm": 0.4339359402656555,
      "learning_rate": 2.9709443099273608e-05,
      "loss": 3.0975,
      "step": 220
    },
    {
      "epoch": 1.585979381443299,
      "grad_norm": 0.4872981011867523,
      "learning_rate": 2.9418886198547215e-05,
      "loss": 3.0634,
      "step": 240
    },
    {
      "epoch": 1.651958762886598,
      "eval_loss": 3.054022789001465,
      "eval_runtime": 141.9729,
      "eval_samples_per_second": 15.186,
      "eval_steps_per_second": 1.902,
      "step": 250
    },
    {
      "epoch": 1.7179381443298969,
      "grad_norm": 0.49877458810806274,
      "learning_rate": 2.9128329297820826e-05,
      "loss": 3.0572,
      "step": 260
    },
    {
      "epoch": 1.8498969072164948,
      "grad_norm": 0.5607386827468872,
      "learning_rate": 2.8837772397094433e-05,
      "loss": 3.0556,
      "step": 280
    },
    {
      "epoch": 1.981855670103093,
      "grad_norm": 0.5989407896995544,
      "learning_rate": 2.854721549636804e-05,
      "loss": 3.0263,
      "step": 300
    },
    {
      "epoch": 1.981855670103093,
      "eval_loss": 3.0120866298675537,
      "eval_runtime": 142.1303,
      "eval_samples_per_second": 15.169,
      "eval_steps_per_second": 1.9,
      "step": 300
    },
    {
      "epoch": 2.1162886597938146,
      "grad_norm": 0.6418359279632568,
      "learning_rate": 2.8256658595641644e-05,
      "loss": 3.0912,
      "step": 320
    },
    {
      "epoch": 2.2482474226804126,
      "grad_norm": 0.6440126299858093,
      "learning_rate": 2.7966101694915255e-05,
      "loss": 3.022,
      "step": 340
    },
    {
      "epoch": 2.3142268041237113,
      "eval_loss": 2.9815657138824463,
      "eval_runtime": 142.2172,
      "eval_samples_per_second": 15.16,
      "eval_steps_per_second": 1.899,
      "step": 350
    },
    {
      "epoch": 2.3802061855670105,
      "grad_norm": 0.6966544389724731,
      "learning_rate": 2.7675544794188862e-05,
      "loss": 2.9651,
      "step": 360
    },
    {
      "epoch": 2.5121649484536084,
      "grad_norm": 0.7001125812530518,
      "learning_rate": 2.738498789346247e-05,
      "loss": 2.9703,
      "step": 380
    },
    {
      "epoch": 2.6441237113402063,
      "grad_norm": 0.8981243371963501,
      "learning_rate": 2.7094430992736077e-05,
      "loss": 2.9446,
      "step": 400
    },
    {
      "epoch": 2.6441237113402063,
      "eval_loss": 2.959857225418091,
      "eval_runtime": 142.1805,
      "eval_samples_per_second": 15.164,
      "eval_steps_per_second": 1.899,
      "step": 400
    },
    {
      "epoch": 2.776082474226804,
      "grad_norm": 0.7532944083213806,
      "learning_rate": 2.6803874092009687e-05,
      "loss": 3.0056,
      "step": 420
    },
    {
      "epoch": 2.908041237113402,
      "grad_norm": 0.7823140621185303,
      "learning_rate": 2.6513317191283295e-05,
      "loss": 2.9796,
      "step": 440
    },
    {
      "epoch": 2.9740206185567013,
      "eval_loss": 2.9382264614105225,
      "eval_runtime": 142.2076,
      "eval_samples_per_second": 15.161,
      "eval_steps_per_second": 1.899,
      "step": 450
    },
    {
      "epoch": 3.042474226804124,
      "grad_norm": 0.6826738715171814,
      "learning_rate": 2.6222760290556902e-05,
      "loss": 3.0802,
      "step": 460
    },
    {
      "epoch": 3.1744329896907217,
      "grad_norm": 0.8402302861213684,
      "learning_rate": 2.593220338983051e-05,
      "loss": 2.9304,
      "step": 480
    },
    {
      "epoch": 3.3063917525773197,
      "grad_norm": 0.7145122289657593,
      "learning_rate": 2.564164648910412e-05,
      "loss": 2.9204,
      "step": 500
    },
    {
      "epoch": 3.3063917525773197,
      "eval_loss": 2.921839714050293,
      "eval_runtime": 142.0907,
      "eval_samples_per_second": 15.173,
      "eval_steps_per_second": 1.9,
      "step": 500
    },
    {
      "epoch": 3.4383505154639176,
      "grad_norm": 0.9528942108154297,
      "learning_rate": 2.5351089588377727e-05,
      "loss": 2.9223,
      "step": 520
    },
    {
      "epoch": 3.5703092783505155,
      "grad_norm": 0.7903649806976318,
      "learning_rate": 2.506053268765133e-05,
      "loss": 2.9467,
      "step": 540
    },
    {
      "epoch": 3.6362886597938147,
      "eval_loss": 2.907062530517578,
      "eval_runtime": 142.2929,
      "eval_samples_per_second": 15.152,
      "eval_steps_per_second": 1.897,
      "step": 550
    },
    {
      "epoch": 3.7022680412371134,
      "grad_norm": 0.8364347815513611,
      "learning_rate": 2.4769975786924938e-05,
      "loss": 2.9273,
      "step": 560
    },
    {
      "epoch": 3.8342268041237113,
      "grad_norm": 0.7407451272010803,
      "learning_rate": 2.4479418886198545e-05,
      "loss": 2.8959,
      "step": 580
    },
    {
      "epoch": 3.966185567010309,
      "grad_norm": 0.7513440251350403,
      "learning_rate": 2.4188861985472156e-05,
      "loss": 2.8801,
      "step": 600
    },
    {
      "epoch": 3.966185567010309,
      "eval_loss": 2.8933985233306885,
      "eval_runtime": 142.4041,
      "eval_samples_per_second": 15.14,
      "eval_steps_per_second": 1.896,
      "step": 600
    },
    {
      "epoch": 4.100618556701031,
      "grad_norm": 0.9168322682380676,
      "learning_rate": 2.3898305084745763e-05,
      "loss": 3.0086,
      "step": 620
    },
    {
      "epoch": 4.232577319587629,
      "grad_norm": 0.7710785269737244,
      "learning_rate": 2.360774818401937e-05,
      "loss": 2.896,
      "step": 640
    },
    {
      "epoch": 4.298556701030928,
      "eval_loss": 2.8829193115234375,
      "eval_runtime": 142.1337,
      "eval_samples_per_second": 15.169,
      "eval_steps_per_second": 1.9,
      "step": 650
    },
    {
      "epoch": 4.364536082474227,
      "grad_norm": 0.8880519866943359,
      "learning_rate": 2.3317191283292978e-05,
      "loss": 2.8863,
      "step": 660
    },
    {
      "epoch": 4.496494845360825,
      "grad_norm": 0.9672977328300476,
      "learning_rate": 2.3026634382566588e-05,
      "loss": 2.8866,
      "step": 680
    },
    {
      "epoch": 4.628453608247423,
      "grad_norm": 0.78196781873703,
      "learning_rate": 2.2736077481840196e-05,
      "loss": 2.8752,
      "step": 700
    },
    {
      "epoch": 4.628453608247423,
      "eval_loss": 2.8724281787872314,
      "eval_runtime": 142.3936,
      "eval_samples_per_second": 15.141,
      "eval_steps_per_second": 1.896,
      "step": 700
    },
    {
      "epoch": 4.760412371134021,
      "grad_norm": 0.7910056710243225,
      "learning_rate": 2.2445520581113803e-05,
      "loss": 2.897,
      "step": 720
    },
    {
      "epoch": 4.892371134020618,
      "grad_norm": 0.8577299118041992,
      "learning_rate": 2.215496368038741e-05,
      "loss": 2.8931,
      "step": 740
    },
    {
      "epoch": 4.958350515463917,
      "eval_loss": 2.8618147373199463,
      "eval_runtime": 141.8287,
      "eval_samples_per_second": 15.201,
      "eval_steps_per_second": 1.904,
      "step": 750
    },
    {
      "epoch": 5.02680412371134,
      "grad_norm": 0.8471532464027405,
      "learning_rate": 2.1864406779661017e-05,
      "loss": 2.9557,
      "step": 760
    },
    {
      "epoch": 5.1587628865979385,
      "grad_norm": 0.9642975330352783,
      "learning_rate": 2.1573849878934625e-05,
      "loss": 2.8517,
      "step": 780
    },
    {
      "epoch": 5.290721649484536,
      "grad_norm": 0.8298130631446838,
      "learning_rate": 2.1283292978208232e-05,
      "loss": 2.8653,
      "step": 800
    },
    {
      "epoch": 5.290721649484536,
      "eval_loss": 2.8545849323272705,
      "eval_runtime": 142.2667,
      "eval_samples_per_second": 15.155,
      "eval_steps_per_second": 1.898,
      "step": 800
    },
    {
      "epoch": 5.422680412371134,
      "grad_norm": 0.8787200450897217,
      "learning_rate": 2.099273607748184e-05,
      "loss": 2.8526,
      "step": 820
    },
    {
      "epoch": 5.554639175257732,
      "grad_norm": 0.8284323215484619,
      "learning_rate": 2.070217917675545e-05,
      "loss": 2.8102,
      "step": 840
    },
    {
      "epoch": 5.6206185567010305,
      "eval_loss": 2.8455398082733154,
      "eval_runtime": 142.2879,
      "eval_samples_per_second": 15.152,
      "eval_steps_per_second": 1.898,
      "step": 850
    },
    {
      "epoch": 5.68659793814433,
      "grad_norm": 0.8855253458023071,
      "learning_rate": 2.0411622276029057e-05,
      "loss": 2.8431,
      "step": 860
    },
    {
      "epoch": 5.818556701030928,
      "grad_norm": 0.8289917707443237,
      "learning_rate": 2.0121065375302664e-05,
      "loss": 2.8579,
      "step": 880
    },
    {
      "epoch": 5.950515463917526,
      "grad_norm": 1.002460241317749,
      "learning_rate": 1.983050847457627e-05,
      "loss": 2.8555,
      "step": 900
    },
    {
      "epoch": 5.950515463917526,
      "eval_loss": 2.8390989303588867,
      "eval_runtime": 142.1753,
      "eval_samples_per_second": 15.164,
      "eval_steps_per_second": 1.899,
      "step": 900
    },
    {
      "epoch": 6.084948453608248,
      "grad_norm": 0.8560864329338074,
      "learning_rate": 1.953995157384988e-05,
      "loss": 2.9777,
      "step": 920
    },
    {
      "epoch": 6.216907216494845,
      "grad_norm": 1.0148895978927612,
      "learning_rate": 1.924939467312349e-05,
      "loss": 2.84,
      "step": 940
    },
    {
      "epoch": 6.282886597938145,
      "eval_loss": 2.831875801086426,
      "eval_runtime": 142.0627,
      "eval_samples_per_second": 15.176,
      "eval_steps_per_second": 1.901,
      "step": 950
    },
    {
      "epoch": 6.3488659793814435,
      "grad_norm": 1.0191588401794434,
      "learning_rate": 1.8958837772397097e-05,
      "loss": 2.8309,
      "step": 960
    },
    {
      "epoch": 6.480824742268041,
      "grad_norm": 0.9770621061325073,
      "learning_rate": 1.8668280871670704e-05,
      "loss": 2.8307,
      "step": 980
    },
    {
      "epoch": 6.612783505154639,
      "grad_norm": 0.987265944480896,
      "learning_rate": 1.8377723970944308e-05,
      "loss": 2.8372,
      "step": 1000
    },
    {
      "epoch": 6.612783505154639,
      "eval_loss": 2.82592511177063,
      "eval_runtime": 141.94,
      "eval_samples_per_second": 15.19,
      "eval_steps_per_second": 1.902,
      "step": 1000
    },
    {
      "epoch": 6.744742268041237,
      "grad_norm": 0.9809473156929016,
      "learning_rate": 1.8087167070217918e-05,
      "loss": 2.7844,
      "step": 1020
    },
    {
      "epoch": 6.876701030927835,
      "grad_norm": 1.0181770324707031,
      "learning_rate": 1.7796610169491526e-05,
      "loss": 2.8378,
      "step": 1040
    },
    {
      "epoch": 6.942680412371134,
      "eval_loss": 2.8199515342712402,
      "eval_runtime": 142.1917,
      "eval_samples_per_second": 15.163,
      "eval_steps_per_second": 1.899,
      "step": 1050
    },
    {
      "epoch": 7.011134020618557,
      "grad_norm": 0.8802642226219177,
      "learning_rate": 1.7506053268765133e-05,
      "loss": 2.9302,
      "step": 1060
    },
    {
      "epoch": 7.143092783505154,
      "grad_norm": 0.8351380228996277,
      "learning_rate": 1.721549636803874e-05,
      "loss": 2.8022,
      "step": 1080
    },
    {
      "epoch": 7.275051546391753,
      "grad_norm": 0.9611413478851318,
      "learning_rate": 1.692493946731235e-05,
      "loss": 2.8197,
      "step": 1100
    },
    {
      "epoch": 7.275051546391753,
      "eval_loss": 2.8149030208587646,
      "eval_runtime": 142.2795,
      "eval_samples_per_second": 15.153,
      "eval_steps_per_second": 1.898,
      "step": 1100
    },
    {
      "epoch": 7.40701030927835,
      "grad_norm": 0.9480294585227966,
      "learning_rate": 1.6634382566585958e-05,
      "loss": 2.8099,
      "step": 1120
    },
    {
      "epoch": 7.5389690721649485,
      "grad_norm": 0.9812799096107483,
      "learning_rate": 1.6343825665859565e-05,
      "loss": 2.8143,
      "step": 1140
    },
    {
      "epoch": 7.604948453608247,
      "eval_loss": 2.8095579147338867,
      "eval_runtime": 142.4431,
      "eval_samples_per_second": 15.136,
      "eval_steps_per_second": 1.895,
      "step": 1150
    },
    {
      "epoch": 7.670927835051547,
      "grad_norm": 0.9303566813468933,
      "learning_rate": 1.6053268765133172e-05,
      "loss": 2.8135,
      "step": 1160
    },
    {
      "epoch": 7.802886597938144,
      "grad_norm": 0.9012117385864258,
      "learning_rate": 1.5762711864406783e-05,
      "loss": 2.8152,
      "step": 1180
    },
    {
      "epoch": 7.934845360824742,
      "grad_norm": 0.9050379991531372,
      "learning_rate": 1.547215496368039e-05,
      "loss": 2.7858,
      "step": 1200
    },
    {
      "epoch": 7.934845360824742,
      "eval_loss": 2.8045854568481445,
      "eval_runtime": 142.508,
      "eval_samples_per_second": 15.129,
      "eval_steps_per_second": 1.895,
      "step": 1200
    },
    {
      "epoch": 8.069278350515464,
      "grad_norm": 0.8114835619926453,
      "learning_rate": 1.5181598062953994e-05,
      "loss": 2.9031,
      "step": 1220
    },
    {
      "epoch": 8.201237113402062,
      "grad_norm": 0.962816059589386,
      "learning_rate": 1.4891041162227603e-05,
      "loss": 2.8296,
      "step": 1240
    },
    {
      "epoch": 8.26721649484536,
      "eval_loss": 2.800682306289673,
      "eval_runtime": 142.2776,
      "eval_samples_per_second": 15.153,
      "eval_steps_per_second": 1.898,
      "step": 1250
    },
    {
      "epoch": 8.33319587628866,
      "grad_norm": 0.9824581742286682,
      "learning_rate": 1.4600484261501212e-05,
      "loss": 2.7843,
      "step": 1260
    },
    {
      "epoch": 8.465154639175259,
      "grad_norm": 0.8731200098991394,
      "learning_rate": 1.4309927360774818e-05,
      "loss": 2.8034,
      "step": 1280
    },
    {
      "epoch": 8.597113402061856,
      "grad_norm": 0.8778661489486694,
      "learning_rate": 1.4019370460048427e-05,
      "loss": 2.7787,
      "step": 1300
    },
    {
      "epoch": 8.597113402061856,
      "eval_loss": 2.7965080738067627,
      "eval_runtime": 142.4903,
      "eval_samples_per_second": 15.131,
      "eval_steps_per_second": 1.895,
      "step": 1300
    },
    {
      "epoch": 8.729072164948454,
      "grad_norm": 0.9251807928085327,
      "learning_rate": 1.3728813559322034e-05,
      "loss": 2.7641,
      "step": 1320
    },
    {
      "epoch": 8.861030927835051,
      "grad_norm": 0.9101951718330383,
      "learning_rate": 1.3438256658595643e-05,
      "loss": 2.7823,
      "step": 1340
    },
    {
      "epoch": 8.92701030927835,
      "eval_loss": 2.792001724243164,
      "eval_runtime": 142.5112,
      "eval_samples_per_second": 15.129,
      "eval_steps_per_second": 1.895,
      "step": 1350
    },
    {
      "epoch": 8.99298969072165,
      "grad_norm": 0.9313698410987854,
      "learning_rate": 1.314769975786925e-05,
      "loss": 2.8175,
      "step": 1360
    },
    {
      "epoch": 9.127422680412371,
      "grad_norm": 1.0290919542312622,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 2.8639,
      "step": 1380
    },
    {
      "epoch": 9.259381443298969,
      "grad_norm": 0.971781849861145,
      "learning_rate": 1.2566585956416464e-05,
      "loss": 2.8129,
      "step": 1400
    },
    {
      "epoch": 9.259381443298969,
      "eval_loss": 2.788658857345581,
      "eval_runtime": 142.0855,
      "eval_samples_per_second": 15.174,
      "eval_steps_per_second": 1.9,
      "step": 1400
    },
    {
      "epoch": 9.391340206185568,
      "grad_norm": 1.0206794738769531,
      "learning_rate": 1.2276029055690073e-05,
      "loss": 2.7671,
      "step": 1420
    },
    {
      "epoch": 9.523298969072165,
      "grad_norm": 1.1145573854446411,
      "learning_rate": 1.198547215496368e-05,
      "loss": 2.7984,
      "step": 1440
    },
    {
      "epoch": 9.589278350515464,
      "eval_loss": 2.784904718399048,
      "eval_runtime": 142.4178,
      "eval_samples_per_second": 15.139,
      "eval_steps_per_second": 1.896,
      "step": 1450
    },
    {
      "epoch": 9.655257731958763,
      "grad_norm": 1.0415503978729248,
      "learning_rate": 1.169491525423729e-05,
      "loss": 2.7675,
      "step": 1460
    },
    {
      "epoch": 9.78721649484536,
      "grad_norm": 0.944385290145874,
      "learning_rate": 1.1404358353510897e-05,
      "loss": 2.7577,
      "step": 1480
    },
    {
      "epoch": 9.91917525773196,
      "grad_norm": 1.0833510160446167,
      "learning_rate": 1.1113801452784504e-05,
      "loss": 2.7877,
      "step": 1500
    },
    {
      "epoch": 9.91917525773196,
      "eval_loss": 2.782000780105591,
      "eval_runtime": 142.3822,
      "eval_samples_per_second": 15.142,
      "eval_steps_per_second": 1.896,
      "step": 1500
    },
    {
      "epoch": 10.05360824742268,
      "grad_norm": 1.0106488466262817,
      "learning_rate": 1.0823244552058111e-05,
      "loss": 2.8602,
      "step": 1520
    },
    {
      "epoch": 10.185567010309278,
      "grad_norm": 1.0497363805770874,
      "learning_rate": 1.0532687651331719e-05,
      "loss": 2.7954,
      "step": 1540
    },
    {
      "epoch": 10.251546391752576,
      "eval_loss": 2.778975009918213,
      "eval_runtime": 142.4398,
      "eval_samples_per_second": 15.136,
      "eval_steps_per_second": 1.896,
      "step": 1550
    },
    {
      "epoch": 10.317525773195877,
      "grad_norm": 0.9205743074417114,
      "learning_rate": 1.0242130750605328e-05,
      "loss": 2.7915,
      "step": 1560
    },
    {
      "epoch": 10.449484536082474,
      "grad_norm": 1.0080397129058838,
      "learning_rate": 9.951573849878935e-06,
      "loss": 2.7638,
      "step": 1580
    },
    {
      "epoch": 10.581443298969072,
      "grad_norm": 1.068213939666748,
      "learning_rate": 9.661016949152542e-06,
      "loss": 2.7725,
      "step": 1600
    },
    {
      "epoch": 10.581443298969072,
      "eval_loss": 2.7768847942352295,
      "eval_runtime": 142.3285,
      "eval_samples_per_second": 15.148,
      "eval_steps_per_second": 1.897,
      "step": 1600
    },
    {
      "epoch": 10.71340206185567,
      "grad_norm": 1.0067243576049805,
      "learning_rate": 9.37046004842615e-06,
      "loss": 2.7284,
      "step": 1620
    },
    {
      "epoch": 10.845360824742269,
      "grad_norm": 1.0089623928070068,
      "learning_rate": 9.079903147699758e-06,
      "loss": 2.7876,
      "step": 1640
    },
    {
      "epoch": 10.911340206185567,
      "eval_loss": 2.773817539215088,
      "eval_runtime": 141.8998,
      "eval_samples_per_second": 15.194,
      "eval_steps_per_second": 1.903,
      "step": 1650
    },
    {
      "epoch": 10.977319587628866,
      "grad_norm": 0.9515064358711243,
      "learning_rate": 8.789346246973365e-06,
      "loss": 2.7423,
      "step": 1660
    },
    {
      "epoch": 11.111752577319587,
      "grad_norm": 0.950332522392273,
      "learning_rate": 8.498789346246974e-06,
      "loss": 2.8731,
      "step": 1680
    },
    {
      "epoch": 11.243711340206186,
      "grad_norm": 1.1353968381881714,
      "learning_rate": 8.208232445520582e-06,
      "loss": 2.7663,
      "step": 1700
    },
    {
      "epoch": 11.243711340206186,
      "eval_loss": 2.7723848819732666,
      "eval_runtime": 142.3769,
      "eval_samples_per_second": 15.143,
      "eval_steps_per_second": 1.896,
      "step": 1700
    },
    {
      "epoch": 11.375670103092784,
      "grad_norm": 0.9879003763198853,
      "learning_rate": 7.917675544794189e-06,
      "loss": 2.7759,
      "step": 1720
    },
    {
      "epoch": 11.507628865979381,
      "grad_norm": 0.966424286365509,
      "learning_rate": 7.627118644067796e-06,
      "loss": 2.7445,
      "step": 1740
    },
    {
      "epoch": 11.57360824742268,
      "eval_loss": 2.7695724964141846,
      "eval_runtime": 142.1348,
      "eval_samples_per_second": 15.169,
      "eval_steps_per_second": 1.9,
      "step": 1750
    },
    {
      "epoch": 11.639587628865979,
      "grad_norm": 0.9897053837776184,
      "learning_rate": 7.336561743341404e-06,
      "loss": 2.7555,
      "step": 1760
    },
    {
      "epoch": 11.771546391752578,
      "grad_norm": 0.9815623164176941,
      "learning_rate": 7.046004842615012e-06,
      "loss": 2.7749,
      "step": 1780
    },
    {
      "epoch": 11.903505154639175,
      "grad_norm": 0.9904330968856812,
      "learning_rate": 6.75544794188862e-06,
      "loss": 2.7496,
      "step": 1800
    },
    {
      "epoch": 11.903505154639175,
      "eval_loss": 2.767789602279663,
      "eval_runtime": 142.3505,
      "eval_samples_per_second": 15.146,
      "eval_steps_per_second": 1.897,
      "step": 1800
    },
    {
      "epoch": 12.037938144329896,
      "grad_norm": 0.9168832898139954,
      "learning_rate": 6.464891041162228e-06,
      "loss": 2.8644,
      "step": 1820
    },
    {
      "epoch": 12.169896907216495,
      "grad_norm": 1.1314703226089478,
      "learning_rate": 6.174334140435836e-06,
      "loss": 2.774,
      "step": 1840
    },
    {
      "epoch": 12.235876288659794,
      "eval_loss": 2.766023635864258,
      "eval_runtime": 142.2016,
      "eval_samples_per_second": 15.162,
      "eval_steps_per_second": 1.899,
      "step": 1850
    },
    {
      "epoch": 12.301855670103093,
      "grad_norm": 1.0247678756713867,
      "learning_rate": 5.883777239709443e-06,
      "loss": 2.7319,
      "step": 1860
    },
    {
      "epoch": 12.43381443298969,
      "grad_norm": 0.9497783184051514,
      "learning_rate": 5.593220338983051e-06,
      "loss": 2.7551,
      "step": 1880
    },
    {
      "epoch": 12.56577319587629,
      "grad_norm": 0.967760443687439,
      "learning_rate": 5.302663438256659e-06,
      "loss": 2.7425,
      "step": 1900
    },
    {
      "epoch": 12.56577319587629,
      "eval_loss": 2.764477252960205,
      "eval_runtime": 142.5701,
      "eval_samples_per_second": 15.122,
      "eval_steps_per_second": 1.894,
      "step": 1900
    },
    {
      "epoch": 12.697731958762887,
      "grad_norm": 0.9977601170539856,
      "learning_rate": 5.0121065375302665e-06,
      "loss": 2.7679,
      "step": 1920
    },
    {
      "epoch": 12.829690721649484,
      "grad_norm": 1.0872191190719604,
      "learning_rate": 4.721549636803875e-06,
      "loss": 2.7636,
      "step": 1940
    },
    {
      "epoch": 12.895670103092783,
      "eval_loss": 2.7633538246154785,
      "eval_runtime": 142.2603,
      "eval_samples_per_second": 15.155,
      "eval_steps_per_second": 1.898,
      "step": 1950
    },
    {
      "epoch": 12.961649484536082,
      "grad_norm": 1.0677176713943481,
      "learning_rate": 4.430992736077482e-06,
      "loss": 2.7498,
      "step": 1960
    },
    {
      "epoch": 13.096082474226804,
      "grad_norm": 1.0081074237823486,
      "learning_rate": 4.14043583535109e-06,
      "loss": 2.9033,
      "step": 1980
    },
    {
      "epoch": 13.228041237113402,
      "grad_norm": 1.080452799797058,
      "learning_rate": 3.849878934624698e-06,
      "loss": 2.7354,
      "step": 2000
    },
    {
      "epoch": 13.228041237113402,
      "eval_loss": 2.7624146938323975,
      "eval_runtime": 142.4074,
      "eval_samples_per_second": 15.14,
      "eval_steps_per_second": 1.896,
      "step": 2000
    },
    {
      "epoch": 13.36,
      "grad_norm": 1.012859582901001,
      "learning_rate": 3.5593220338983053e-06,
      "loss": 2.7211,
      "step": 2020
    },
    {
      "epoch": 13.491958762886599,
      "grad_norm": 0.938498318195343,
      "learning_rate": 3.268765133171913e-06,
      "loss": 2.7452,
      "step": 2040
    },
    {
      "epoch": 13.557938144329897,
      "eval_loss": 2.761392116546631,
      "eval_runtime": 142.1968,
      "eval_samples_per_second": 15.162,
      "eval_steps_per_second": 1.899,
      "step": 2050
    },
    {
      "epoch": 13.623917525773196,
      "grad_norm": 1.1031407117843628,
      "learning_rate": 2.9782082324455206e-06,
      "loss": 2.747,
      "step": 2060
    },
    {
      "epoch": 13.755876288659794,
      "grad_norm": 1.0445659160614014,
      "learning_rate": 2.6876513317191287e-06,
      "loss": 2.7527,
      "step": 2080
    },
    {
      "epoch": 13.887835051546391,
      "grad_norm": 0.8946414589881897,
      "learning_rate": 2.397094430992736e-06,
      "loss": 2.7578,
      "step": 2100
    },
    {
      "epoch": 13.887835051546391,
      "eval_loss": 2.76041579246521,
      "eval_runtime": 142.2691,
      "eval_samples_per_second": 15.154,
      "eval_steps_per_second": 1.898,
      "step": 2100
    },
    {
      "epoch": 14.022268041237114,
      "grad_norm": 1.0835866928100586,
      "learning_rate": 2.1065375302663436e-06,
      "loss": 2.8678,
      "step": 2120
    },
    {
      "epoch": 14.154226804123711,
      "grad_norm": 0.9418179392814636,
      "learning_rate": 1.8159806295399517e-06,
      "loss": 2.7251,
      "step": 2140
    },
    {
      "epoch": 14.22020618556701,
      "eval_loss": 2.75993275642395,
      "eval_runtime": 142.4899,
      "eval_samples_per_second": 15.131,
      "eval_steps_per_second": 1.895,
      "step": 2150
    },
    {
      "epoch": 14.286185567010309,
      "grad_norm": 1.0084596872329712,
      "learning_rate": 1.5254237288135594e-06,
      "loss": 2.7518,
      "step": 2160
    },
    {
      "epoch": 14.418144329896908,
      "grad_norm": 1.0054141283035278,
      "learning_rate": 1.234866828087167e-06,
      "loss": 2.7372,
      "step": 2180
    },
    {
      "epoch": 14.550103092783505,
      "grad_norm": 0.9998800158500671,
      "learning_rate": 9.44309927360775e-07,
      "loss": 2.7424,
      "step": 2200
    },
    {
      "epoch": 14.550103092783505,
      "eval_loss": 2.7596442699432373,
      "eval_runtime": 142.5058,
      "eval_samples_per_second": 15.129,
      "eval_steps_per_second": 1.895,
      "step": 2200
    },
    {
      "epoch": 14.682061855670103,
      "grad_norm": 0.9615015983581543,
      "learning_rate": 6.537530266343825e-07,
      "loss": 2.7386,
      "step": 2220
    },
    {
      "epoch": 14.8140206185567,
      "grad_norm": 0.9761168360710144,
      "learning_rate": 3.631961259079903e-07,
      "loss": 2.753,
      "step": 2240
    },
    {
      "epoch": 14.88,
      "eval_loss": 2.7593941688537598,
      "eval_runtime": 142.3023,
      "eval_samples_per_second": 15.151,
      "eval_steps_per_second": 1.897,
      "step": 2250
    },
    {
      "epoch": 14.9459793814433,
      "grad_norm": 0.948445200920105,
      "learning_rate": 7.263922518159807e-08,
      "loss": 2.763,
      "step": 2260
    }
  ],
  "logging_steps": 20,
  "max_steps": 2265,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.690213216481444e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
